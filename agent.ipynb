{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!!pip install litellm\n",
    "\n",
    "# Important!!!\n",
    "#\n",
    "# <---- Set your 'OPENAI_API_KEY' as a secret over there with the \"key\" icon\n",
    "#\n",
    "#\n",
    "import os\n",
    "from google.colab import userdata\n",
    "api_key = userdata.get('OPENAI_API_KEY')\n",
    "os.environ['OPENAI_API_KEY'] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from litellm import completion\n",
    "from typing import List, Dict\n",
    "import json\n",
    "import re\n",
    "\n",
    "\n",
    "def generate_response(messages: List[Dict]) -> str:\n",
    "    \"\"\"Call LLM to get response\"\"\"\n",
    "    response = completion(\n",
    "        model=\"openai/gpt-4o\",\n",
    "        messages=messages,\n",
    "        max_tokens=1024\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "what_to_help_with = input(\"What do you need help with?\")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an expert on python programming.  When given a description of a function, create a python program that meets that description.  When you respond, respond only with a json dictionarey that has one entry for the code and different entries for any commentary\"},\n",
    "    {\"role\": \"user\", \"content\": what_to_help_with}\n",
    "]\n",
    "\n",
    "response = generate_response(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def construct_prompt(memory, user_input, system_rules):\n",
    "    \"\"\"Combines memory, user input, and system rules into a prompt.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Memory: {memory}\n",
    "    User Input: {user_input}\n",
    "    System Rules: {system_rules}\n",
    "\n",
    "    Please provide your next action in JSON format:\n",
    "    {{\n",
    "        \"action\": \"action_name\",\n",
    "        \"parameters\": {{\n",
    "            \"param1\": \"value1\",\n",
    "            \"param2\": \"value2\"\n",
    "        }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n",
    "def generate_response(prompt):\n",
    "    \"\"\"Sends the prompt to the LLM and retrieves a response.\"\"\"\n",
    "    # Replace with your actual LLM call\n",
    "    response = \"Replace with LLM response\"\n",
    "    return response\n",
    "\n",
    "def parse_response(response):\n",
    "    \"\"\"Extracts action and parameters from the LLM response.\"\"\"\n",
    "    try:\n",
    "        response_json = json.loads(response)\n",
    "        action = response_json[\"action\"]\n",
    "        parameters = response_json[\"parameters\"]\n",
    "    except (json.JSONDecodeError, KeyError):\n",
    "        return None, None\n",
    "    return action, parameters\n",
    "\n",
    "def execute_action(action, parameters):\n",
    "    \"\"\"Executes the action with the given parameters.\"\"\"\n",
    "    if action == \"list_files\":\n",
    "        files = os.listdir(parameters.get(\"directory\", \".\"))\n",
    "        return f\"Files in directory: {', '.join(files)}\"\n",
    "    elif action == \"read_file\":\n",
    "        try:\n",
    "            with open(parameters[\"file_path\"], \"r\") as f:\n",
    "                content = f.read()\n",
    "            return f\"File content: {content}\"\n",
    "        except FileNotFoundError:\n",
    "            return \"File not found.\"\n",
    "    # Add more actions as needed\n",
    "    else:\n",
    "        return \"Invalid action.\"\n",
    "\n",
    "def convert_result_to_string(result):\n",
    "    \"\"\"Formats the result into a string.\"\"\"\n",
    "    return str(result)\n",
    "\n",
    "def agent_loop(memory, user_input, system_rules):\n",
    "    \"\"\"Main agent loop.\"\"\"\n",
    "    while True:\n",
    "        prompt = construct_prompt(memory, user_input, system_rules)\n",
    "        response = generate_response(prompt)\n",
    "        action, parameters = parse_response(response)\n",
    "\n",
    "        if action is None:\n",
    "            print(\"Invalid response format.\")\n",
    "            break\n",
    "\n",
    "        result = execute_action(action, parameters)\n",
    "        result_string = convert_result_to_string(result)\n",
    "\n",
    "        # Update memory, check for termination conditions, etc.\n",
    "        memory += f\"\\nAction: {action}, Result: {result_string}\"\n",
    "\n",
    "        if action == \"terminate\":\n",
    "            break\n",
    "\n",
    "        # Get next user input or continue based on logic\n",
    "        user_input = input(\"Enter your next query: \")\n",
    "\n",
    "    print(\"Agent loop terminated.\")\n",
    "\n",
    "# Example usage\n",
    "memory = \"\"\n",
    "user_input = \"List files in the current directory.\"\n",
    "system_rules = \"You can list files, read files, and answer questions about them.\"\n",
    "\n",
    "agent_loop(memory, user_input, system_rules)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
